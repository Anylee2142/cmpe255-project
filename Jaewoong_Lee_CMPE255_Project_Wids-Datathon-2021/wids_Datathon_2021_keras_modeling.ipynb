{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "qSwG6SXjb9O4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.utils import resample\n",
    "\n",
    "url_1 = 'https://raw.githubusercontent.com/takanju/wids_datathon_2021/master/TrainingWiDS2021.csv'\n",
    "train_local_path = '../data/TrainingWiDS2021.csv'\n",
    "url_2 = 'https://raw.githubusercontent.com/takanju/wids_datathon_2021/master/UnlabeledWiDS2021.csv'\n",
    "test_local_path = '../data/UnlabeledWiDS2021.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # Disable GPU\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Simpler model = CPU faster than GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "2ts3yh6Bov2i"
   },
   "outputs": [],
   "source": [
    "# Splitted data to make same shape of both test and train so that we can apply pre processing on both\n",
    "# Ref : https://www.kaggle.com/siavrez/2020fatures\n",
    "medical_data = pd.read_csv(train_local_path, error_bad_lines=False, index_col=0)\n",
    "test_df = pd.read_csv(test_local_path, error_bad_lines=False, index_col=0)\n",
    "y = medical_data[\"diabetes_mellitus\"]\n",
    "medical_data = medical_data.drop([\"diabetes_mellitus\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znvkr_fsxv-U",
    "outputId": "bdd1e49c-80f9-4112-8ff5-b1d1c36fe582"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130157, 179)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "K1I81SaJE4CR"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preProcessing1(df: pd.DataFrame, y:pd.Series) -> pd.DataFrame:\n",
    "  columns=df.columns\n",
    "\n",
    "  #dropping column which are either irrelevant or around 50% of missing values\n",
    "  df=df.drop(['encounter_id', 'hospital_id', 'icu_id', 'albumin_apache','bilirubin_apache','fio2_apache','paco2_apache','paco2_for_ph_apache','pao2_apache','ph_apache', 'urineoutput_apache'], axis=1)\n",
    "\n",
    "  #separating categorical & numerical features\n",
    "  df_cat = df.select_dtypes(\"object\")\n",
    "  df_num = df.select_dtypes(\"number\")\n",
    "  cat_cal = df_cat.columns\n",
    "  num_cal = df_num.columns\n",
    "  \n",
    "  #imputing categorical features by mode\n",
    "  impute_size1=SimpleImputer(strategy=\"most_frequent\") \n",
    "  df_cat = impute_size1.fit_transform(df_cat)\n",
    "  df_cat = pd.DataFrame(df_cat, columns = cat_cal)\n",
    "\n",
    "  #imputing numerical features by mean\n",
    "  impute_size2=SimpleImputer(missing_values=np.nan, strategy=\"mean\") \n",
    "  df_num = impute_size2.fit_transform(df_num)\n",
    "\n",
    "  df_num = pd.DataFrame(df_num, columns = num_cal)\n",
    "  #concatenating both categorical & numerical features\n",
    "#   df = df_cat.join(df_num)\n",
    "#   return df, [impute_size1, impute_size2 ]\n",
    "  \n",
    "  #Standardization\n",
    "  scaler = StandardScaler()\n",
    "  scaled_df = scaler.fit_transform(df_num)\n",
    "  df_num_scale = pd.DataFrame(data=scaled_df, columns=df_num.columns)\n",
    "\n",
    "  #One Hot Encoding\n",
    "  df_cat = pd.get_dummies(df_cat)\n",
    "  df = df_cat.join(df_num_scale)\n",
    "\n",
    "#   return df, [impute_size1, impute_size2, scaler, {\"OHE\":(cat_cal, df_cat_encod, onehotencoder)}]\n",
    "  return df, [impute_size1, impute_size2, scaler, list(cat_cal)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "WyD1c25LE-jQ"
   },
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from scipy import stats, special\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Ref: https://www.kaggle.com/shashankasubrahmanya/missing-data-imputation-using-regression\n",
    "\n",
    "# filling missing values based on linear regression and the most correlated variables\n",
    "# linear regression -> F-test (which columns are mostly related with the given target column, other than \"diabetes\")\n",
    "# Multi-colinearity\n",
    "# target = diabetes\n",
    "# Remove features which has more than 50% percentage of missing values\n",
    "# Return reduced dataset\n",
    "\n",
    "# Linear Regression\n",
    "def fillna_using_linear_model(df: pd.DataFrame):\n",
    "    fea_cols=[]\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype=='float64':\n",
    "            fea_cols.append(col)\n",
    "\n",
    "    correl = df[fea_cols].corr()\n",
    "\n",
    "    for col in tqdm(fea_cols):\n",
    "        nan_ratio = df[col].isnull().sum() / df.shape[0]\n",
    "        if nan_ratio > 0:\n",
    "            best_nan_ratio = nan_ratio\n",
    "            best_col = None\n",
    "            for id in correl.loc[(correl[col] > 0.7) | (correl[col] < -0.7), col].index:\n",
    "                nan_temp_ratio = df[id].isnull().sum() / df.shape[0]\n",
    "                if best_nan_ratio > nan_temp_ratio:\n",
    "                    best_nan_ratio = nan_temp_ratio\n",
    "                    best_col = id\n",
    "            if best_col != None:\n",
    "                sub = df[[col, best_col]].copy()\n",
    "                sub = sub.dropna()\n",
    "                reg = LinearRegression(fit_intercept=True).fit(np.expand_dims(sub[best_col], axis=1), sub[col])\n",
    "                print(reg.score(np.expand_dims(sub[best_col], axis=1), sub[col]))\n",
    "                if reg.score(np.expand_dims(sub[best_col], axis=1), sub[col])>0.7:\n",
    "                    if df.loc[(~df[best_col].isnull()) & (df[col].isnull()), col].shape[0] > 0:\n",
    "                        df.loc[(~df[best_col].isnull()) & (df[col].isnull()), col] = \\\n",
    "                        reg.predict(np.expand_dims(df.loc[(~df[best_col].isnull()) & (df[col].isnull()), best_col], axis=1))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preProcessing2(df: pd.DataFrame, y:pd.Series) -> pd.DataFrame:\n",
    "  columns=df.columns\n",
    "\n",
    "# Replace values such as +,- ininity with nan\n",
    "  df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Linear regression\n",
    "  linReg = fillna_using_linear_model(df)\n",
    "\n",
    "# Simple Imputing\n",
    "  imputer = SimpleImputer(strategy=\"mean\")\n",
    "  imputed_df = pd.DataFrame(imputer.fit_transform(linReg.values))\n",
    "\n",
    "# Standardization\n",
    "  scaler = StandardScaler()\n",
    "  scaled_df = scaler.fit_transform(imputed_df)\n",
    "  df= pd.DataFrame(data=scaled_df, columns=columns)\n",
    "  \n",
    "  return df, [imputer, scaler]\n",
    "\n",
    "# dd = preProcessing2(medical_data.copy(), y)\n",
    "# dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "bzP35KLaFFYP"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer # MICE \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from discretization import MDLP\n",
    "# from mdlp.discretization import MDLP\n",
    "\n",
    "def preProcessing3(df: pd.DataFrame, y: pd.Series) -> pd.DataFrame:\n",
    "  columns = df.columns\n",
    "\n",
    "  # Log transform for skewing data\n",
    "  # https://stats.stackexchange.com/questions/267078/why-is-skewed-data-not-preferred-for-modelling\n",
    "  # https://stats.stackexchange.com/questions/299154/the-benefit-of-unskewing-skewed-data\n",
    "  logs_transform_list = ['d1_bilirubin_min', 'd1_bilirubin_max', 'd1_glucose_max', 'h1_bilirubin_max', 'h1_bilirubin_min', 'h1_bun_max', 'h1_bun_min']\n",
    "  df[logs_transform_list] = np.log2(df[logs_transform_list])\n",
    "\n",
    "  # Simple Imputing\n",
    "  imputer = SimpleImputer(strategy=\"mean\")\n",
    "  imputed_df = imputer.fit_transform(df.values)\n",
    "\n",
    "  # Standardization\n",
    "  scaler = StandardScaler()\n",
    "  imputed_scaled_df = scaler.fit_transform(imputed_df)\n",
    "\n",
    "  df = pd.DataFrame(columns=columns, data=imputed_scaled_df)\n",
    "\n",
    "  return df, [{\"columns\": logs_transform_list, \"transform\": np.log2}, imputer, scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "NScHQ9DQFQLN"
   },
   "outputs": [],
   "source": [
    "#ref: https://www.kaggle.com/lhagiimn/7th-place-solution-wids-2021\n",
    "#ref:https://www.kaggle.com/letianyu/wids-2021-notebook\n",
    "\n",
    "def remove_NaN_Values(df, threshold):\n",
    "    # store the name of columns\n",
    "    # drop the same for the test set (later)\n",
    "    NaN_cols = []\n",
    "    for col in df.columns:\n",
    "        NaN_ratio = df[col].isnull().sum() / df.shape[0]\n",
    "        if NaN_ratio >= threshold:\n",
    "            NaN_cols.append(col)\n",
    "    df = df.drop(NaN_cols, axis=1)\n",
    "    return df,NaN_cols\n",
    "\n",
    "def preProcessing4(df: pd.DataFrame, y: pd.Series) -> pd.DataFrame:\n",
    "    columns = df.columns\n",
    "\n",
    "    Removed_NaN_df,NaN_cols = remove_NaN_Values(df,0.5)\n",
    "\n",
    "    return Removed_NaN_df, NaN_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpfFhyXBF2ld"
   },
   "source": [
    "# Combine all pre processings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQZfFMxY8bqn",
    "outputId": "8cc023d3-fecc-4e59-87a1-33e18f25a928"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 13/45 [00:00<00:00, 121.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563520769020351\n",
      "0.9933743343176455\n",
      "0.9932092949406127\n",
      "0.5556868832041206\n",
      "0.6232299891476356\n",
      "0.5630410484129751\n",
      "0.6303842387953887\n",
      "0.5152979908671131\n",
      "0.9928207761805053\n",
      "0.9913514557124004\n",
      "0.5060654310356865\n",
      "0.9694702204192752\n",
      "0.9658512634599362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 139.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6155171814780587\n",
      "0.49954907647888736\n",
      "0.716253639395113\n",
      "0.7618525388005946\n",
      "0.972967652946108\n",
      "0.9928344337233268\n",
      "0.6277670731828182\n",
      "Percent of Nans: 0.0\n"
     ]
    }
   ],
   "source": [
    "df1 = medical_data.iloc[:, :45]\n",
    "prep_df1, tf1 = preProcessing1(df1, y)\n",
    "prep_df1.index = medical_data.index\n",
    "\n",
    "df2 = medical_data.iloc[:, 45:90]\n",
    "prep_df2, tf2 = preProcessing2(df2, y)\n",
    "prep_df2.index = medical_data.index\n",
    "\n",
    "df3 = medical_data.iloc[:, 90:135]\n",
    "prep_df3, tf3 = preProcessing3(df3, y)\n",
    "prep_df3.index = medical_data.index\n",
    "\n",
    "df4 = medical_data.iloc[:, 135:]\n",
    "prep_df4, tf4 = preProcessing4(df4, y)\n",
    "prep_df4.index = prep_df1.index\n",
    "\n",
    "prep_df = pd.concat([prep_df1, prep_df2, prep_df3, prep_df4], axis=1)\n",
    "\n",
    "print(f'Percent of Nans: {round(prep_df.copy().isna().sum().sum()/len(prep_df.copy()), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "0WM4CTqT6tNg",
    "outputId": "8cf1f5c7-c221-49b7-d255-c0b9ad6c7775"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity_African American</th>\n",
       "      <th>ethnicity_Asian</th>\n",
       "      <th>ethnicity_Caucasian</th>\n",
       "      <th>ethnicity_Hispanic</th>\n",
       "      <th>ethnicity_Native American</th>\n",
       "      <th>ethnicity_Other/Unknown</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>hospital_admit_source_Acute Care/Floor</th>\n",
       "      <th>hospital_admit_source_Chest Pain Center</th>\n",
       "      <th>...</th>\n",
       "      <th>h1_calcium_max</th>\n",
       "      <th>h1_calcium_min</th>\n",
       "      <th>h1_creatinine_max</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.610996e-15</td>\n",
       "      <td>9.092629e-15</td>\n",
       "      <td>-6.395302e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.457641e-01</td>\n",
       "      <td>8.572557e-01</td>\n",
       "      <td>-1.391968e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.610996e-15</td>\n",
       "      <td>9.092629e-15</td>\n",
       "      <td>-6.395302e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.610996e-15</td>\n",
       "      <td>9.092629e-15</td>\n",
       "      <td>-6.395302e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.610996e-15</td>\n",
       "      <td>9.092629e-15</td>\n",
       "      <td>-6.395302e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity_African American  ethnicity_Asian  ethnicity_Caucasian  \\\n",
       "1                           0                0                    1   \n",
       "2                           0                0                    1   \n",
       "3                           0                0                    1   \n",
       "4                           0                0                    1   \n",
       "5                           0                0                    1   \n",
       "\n",
       "   ethnicity_Hispanic  ethnicity_Native American  ethnicity_Other/Unknown  \\\n",
       "1                   0                          0                        0   \n",
       "2                   0                          0                        0   \n",
       "3                   0                          0                        0   \n",
       "4                   0                          0                        0   \n",
       "5                   0                          0                        0   \n",
       "\n",
       "   gender_F  gender_M  hospital_admit_source_Acute Care/Floor  \\\n",
       "1         0         1                                       0   \n",
       "2         1         0                                       0   \n",
       "3         1         0                                       0   \n",
       "4         1         0                                       0   \n",
       "5         0         1                                       0   \n",
       "\n",
       "   hospital_admit_source_Chest Pain Center             ...               \\\n",
       "1                                        0             ...                \n",
       "2                                        0             ...                \n",
       "3                                        0             ...                \n",
       "4                                        0             ...                \n",
       "5                                        0             ...                \n",
       "\n",
       "   h1_calcium_max  h1_calcium_min  h1_creatinine_max  aids  cirrhosis  \\\n",
       "1    4.610996e-15    9.092629e-15      -6.395302e-16     0          0   \n",
       "2    8.457641e-01    8.572557e-01      -1.391968e+00     0          0   \n",
       "3    4.610996e-15    9.092629e-15      -6.395302e-16     0          0   \n",
       "4    4.610996e-15    9.092629e-15      -6.395302e-16     0          0   \n",
       "5    4.610996e-15    9.092629e-15      -6.395302e-16     0          0   \n",
       "\n",
       "   hepatic_failure  immunosuppression  leukemia  lymphoma  \\\n",
       "1                0                  0         0         0   \n",
       "2                0                  0         0         0   \n",
       "3                0                  0         0         0   \n",
       "4                0                  0         0         0   \n",
       "5                0                  0         0         0   \n",
       "\n",
       "   solid_tumor_with_metastasis  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "5                            0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "cat_cols = []\n",
    "for each in prep_df.columns:\n",
    "    for origin in tf1[-1]:\n",
    "        if origin in each:\n",
    "            cat_cols.append(each)\n",
    "\n",
    "cat_df = prep_df[cat_cols]\n",
    "num_df = prep_df.drop(cat_cols, axis=1)\n",
    "prep_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "X = csc_matrix(prep_df.values)\n",
    "y_ = y.values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_, stratify=y_, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#multimetric-scoring\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py\n",
    "\n",
    "# Ensemble Methods\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier\n",
    "\n",
    "# GridSearch + CV on non-sklearn models\n",
    "# https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "# scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'F1-score': make_scorer(f1_score), 'Recall': make_scorer(recall_score), 'Precision': make_scorer(precision_score)}\n",
    "scoring = {'AUC': 'roc_auc'}\n",
    "\n",
    "def grid(estimator, scoring, cv, X, y, verbose):\n",
    "    return GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    scoring = scoring,\n",
    "    cv = cv,\n",
    "    verbose = verbose,\n",
    "    return_train_score = True,\n",
    "    refit=\"AUC\",\n",
    "    n_jobs = -3 # If GPU, set to 1\n",
    "    ).fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = accuracy_score(prep_test, y_pred)\n",
    "# f1 = f1_score(prep_test, y_pred)\n",
    "# rec = recall_score(prep_test, y_pred)\n",
    "# prec = precision_score(prep_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Jaewoong] Convert to CLF\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/\n",
    "# https://stackoverflow.com/questions/63381301/how-many-neurons-should-be-in-the-last-layer-of-the-neural-network\n",
    "# https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import * \n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD, Adagrad, Adam, Nadam\n",
    "\n",
    "def return_optimizer(name):\n",
    "    if name == \"SGD\":\n",
    "        return SGD\n",
    "    elif name == \"Adagrad\":\n",
    "        return Adagrad\n",
    "    elif name == \"Adam\":\n",
    "        return Adam\n",
    "    elif name == \"Nadam\":\n",
    "        return Nadam\n",
    "\n",
    "def buildmodel(optimizer, learn_rate, init_mode, activation, dropout_rate, neurons):\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=X_train.shape[1], kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons//2, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons//3, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons//4, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    opt_object = return_optimizer(optimizer)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt_object(lr=learn_rate), metrics=['AUC'])\n",
    "    return model\n",
    "    \n",
    "# params = {\n",
    "#     \"epochs\": [100, 200, 300],\n",
    "#     \"optimizer\": ['SGD', 'Adagrad', 'Adam',],\n",
    "#     \"learn_rate\": [0.1, 0.01],\n",
    "#     \"init_mode\": ['glorot_normal', 'he_normal', 'lecun_uniform'],\n",
    "#     \"activation\": ['relu', 'tanh', 'sigmoid'],\n",
    "#     \"dropout_rate\": [0.1, 0.2, 0.3],\n",
    "#     \"neurons\": [10, 50, 100, 200],\n",
    "#     \"batch_size\": [1000, 5000, 10000]\n",
    "# }\n",
    "params = {\n",
    "    \"epochs\": [300],\n",
    "    \"optimizer\": ['SGD', 'Adam',],\n",
    "    \"learn_rate\": [0.1, 0.01],\n",
    "    \"init_mode\": ['glorot_normal', 'he_normal'],\n",
    "    \"activation\": ['relu'],\n",
    "    \"dropout_rate\": [0.1, 0.3],\n",
    "    \"neurons\": [50, 100],\n",
    "    \"batch_size\": [5000]\n",
    "}\n",
    "# params = {\n",
    "#     \"epochs\": [1],\n",
    "#     \"optimizer\": ['SGD'],\n",
    "#     \"learn_rate\": [0.1],\n",
    "#     \"init_mode\": ['glorot_normal'],\n",
    "#     \"activation\": ['relu'],\n",
    "#     \"dropout_rate\": [0.1],\n",
    "#     \"neurons\": [10],\n",
    "#     \"batch_size\": [10000]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "qWeBNdNqFXts"
   },
   "outputs": [],
   "source": [
    "# Check if n_jobs impacts GPU\n",
    "estimator= KerasClassifier(build_fn=buildmodel, verbose=1)\n",
    "estimator._estimator_type = \"classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Epoch 1/300\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.5810 - auc: 0.4585\n",
      "Epoch 2/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.5300 - auc: 0.5390\n",
      "Epoch 3/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.5105 - auc: 0.6104\n",
      "Epoch 4/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4933 - auc: 0.6639\n",
      "Epoch 5/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4798 - auc: 0.6983\n",
      "Epoch 6/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4695 - auc: 0.7244\n",
      "Epoch 7/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4606 - auc: 0.7436\n",
      "Epoch 8/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4529 - auc: 0.7527\n",
      "Epoch 9/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4474 - auc: 0.7621\n",
      "Epoch 10/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4450 - auc: 0.7684\n",
      "Epoch 11/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4402 - auc: 0.7745\n",
      "Epoch 12/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4357 - auc: 0.7805\n",
      "Epoch 13/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4351 - auc: 0.7811\n",
      "Epoch 14/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4312 - auc: 0.7881\n",
      "Epoch 15/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4282 - auc: 0.7887\n",
      "Epoch 16/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4261 - auc: 0.7944\n",
      "Epoch 17/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4248 - auc: 0.7937\n",
      "Epoch 18/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4236 - auc: 0.7965\n",
      "Epoch 19/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4202 - auc: 0.8002\n",
      "Epoch 20/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4214 - auc: 0.8002\n",
      "Epoch 21/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4197 - auc: 0.7997\n",
      "Epoch 22/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4187 - auc: 0.8026\n",
      "Epoch 23/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4178 - auc: 0.8034\n",
      "Epoch 24/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4163 - auc: 0.8047\n",
      "Epoch 25/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4170 - auc: 0.8035\n",
      "Epoch 26/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4124 - auc: 0.8087\n",
      "Epoch 27/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4133 - auc: 0.8108\n",
      "Epoch 28/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4145 - auc: 0.8084\n",
      "Epoch 29/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4105 - auc: 0.8100\n",
      "Epoch 30/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4096 - auc: 0.8128\n",
      "Epoch 31/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4105 - auc: 0.8109\n",
      "Epoch 32/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4121 - auc: 0.8116\n",
      "Epoch 33/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4088 - auc: 0.8117\n",
      "Epoch 34/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4078 - auc: 0.8131\n",
      "Epoch 35/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4049 - auc: 0.8167\n",
      "Epoch 36/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4067 - auc: 0.8169\n",
      "Epoch 37/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4053 - auc: 0.8166\n",
      "Epoch 38/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4032 - auc: 0.8203\n",
      "Epoch 39/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4046 - auc: 0.8192\n",
      "Epoch 40/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4059 - auc: 0.8168\n",
      "Epoch 41/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4002 - auc: 0.8233\n",
      "Epoch 42/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4030 - auc: 0.8206\n",
      "Epoch 43/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4030 - auc: 0.8216\n",
      "Epoch 44/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4032 - auc: 0.8223\n",
      "Epoch 45/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4036 - auc: 0.8212\n",
      "Epoch 46/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3986 - auc: 0.8242\n",
      "Epoch 47/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3996 - auc: 0.8239\n",
      "Epoch 48/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4014 - auc: 0.8218\n",
      "Epoch 49/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4012 - auc: 0.8232\n",
      "Epoch 50/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4011 - auc: 0.8221\n",
      "Epoch 51/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3974 - auc: 0.8255\n",
      "Epoch 52/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4003 - auc: 0.8240\n",
      "Epoch 53/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4015 - auc: 0.8227\n",
      "Epoch 54/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4032 - auc: 0.8228\n",
      "Epoch 55/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3980 - auc: 0.8256\n",
      "Epoch 56/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3966 - auc: 0.8279\n",
      "Epoch 57/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3990 - auc: 0.8253\n",
      "Epoch 58/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3959 - auc: 0.8265\n",
      "Epoch 59/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3982 - auc: 0.8271\n",
      "Epoch 60/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3991 - auc: 0.8255\n",
      "Epoch 61/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3956 - auc: 0.8277\n",
      "Epoch 62/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3946 - auc: 0.8288\n",
      "Epoch 63/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3961 - auc: 0.8295\n",
      "Epoch 64/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3981 - auc: 0.8265\n",
      "Epoch 65/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3957 - auc: 0.8283\n",
      "Epoch 66/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3975 - auc: 0.8276\n",
      "Epoch 67/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3923 - auc: 0.8333\n",
      "Epoch 68/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3948 - auc: 0.8295\n",
      "Epoch 69/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3967 - auc: 0.8288\n",
      "Epoch 70/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3964 - auc: 0.8283\n",
      "Epoch 71/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3935 - auc: 0.8311\n",
      "Epoch 72/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3965 - auc: 0.8284\n",
      "Epoch 73/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3969 - auc: 0.8283\n",
      "Epoch 74/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3928 - auc: 0.8314\n",
      "Epoch 75/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3944 - auc: 0.8312\n",
      "Epoch 76/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3956 - auc: 0.8293\n",
      "Epoch 77/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3954 - auc: 0.8295\n",
      "Epoch 78/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3931 - auc: 0.8321\n",
      "Epoch 79/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3906 - auc: 0.8336\n",
      "Epoch 80/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3889 - auc: 0.8343\n",
      "Epoch 81/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3910 - auc: 0.8319\n",
      "Epoch 82/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3950 - auc: 0.8303\n",
      "Epoch 83/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3932 - auc: 0.8312\n",
      "Epoch 84/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3911 - auc: 0.8330\n",
      "Epoch 85/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3908 - auc: 0.8332\n",
      "Epoch 86/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3901 - auc: 0.8351\n",
      "Epoch 87/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3899 - auc: 0.8352\n",
      "Epoch 88/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3916 - auc: 0.8338\n",
      "Epoch 89/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3912 - auc: 0.8336\n",
      "Epoch 90/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3923 - auc: 0.8324\n",
      "Epoch 91/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3916 - auc: 0.8332\n",
      "Epoch 92/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3923 - auc: 0.8323\n",
      "Epoch 93/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3891 - auc: 0.8351\n",
      "Epoch 94/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3917 - auc: 0.8326\n",
      "Epoch 95/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3905 - auc: 0.8347\n",
      "Epoch 96/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3888 - auc: 0.8357\n",
      "Epoch 97/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3910 - auc: 0.8337\n",
      "Epoch 98/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3908 - auc: 0.8350\n",
      "Epoch 99/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3902 - auc: 0.8344\n",
      "Epoch 100/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3893 - auc: 0.8360\n",
      "Epoch 101/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3923 - auc: 0.8336\n",
      "Epoch 102/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3915 - auc: 0.8351\n",
      "Epoch 103/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3914 - auc: 0.8357\n",
      "Epoch 104/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3893 - auc: 0.8355\n",
      "Epoch 105/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3881 - auc: 0.8362\n",
      "Epoch 106/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3913 - auc: 0.8353\n",
      "Epoch 107/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3889 - auc: 0.8361\n",
      "Epoch 108/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3907 - auc: 0.8347\n",
      "Epoch 109/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3887 - auc: 0.8361\n",
      "Epoch 110/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3901 - auc: 0.8366\n",
      "Epoch 111/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3911 - auc: 0.8343\n",
      "Epoch 112/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3919 - auc: 0.8339\n",
      "Epoch 113/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3873 - auc: 0.8370\n",
      "Epoch 114/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3860 - auc: 0.8387\n",
      "Epoch 115/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3904 - auc: 0.8351\n",
      "Epoch 116/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3901 - auc: 0.8369\n",
      "Epoch 117/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3863 - auc: 0.8386\n",
      "Epoch 118/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3892 - auc: 0.8357\n",
      "Epoch 119/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3889 - auc: 0.8375\n",
      "Epoch 120/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3874 - auc: 0.8390\n",
      "Epoch 121/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3867 - auc: 0.8372\n",
      "Epoch 122/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3837 - auc: 0.8392\n",
      "Epoch 123/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3850 - auc: 0.8388\n",
      "Epoch 124/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3863 - auc: 0.8390\n",
      "Epoch 125/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3834 - auc: 0.8403\n",
      "Epoch 126/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3842 - auc: 0.8406\n",
      "Epoch 127/300\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3833 - auc: 0.8404\n",
      "Epoch 128/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3859 - auc: 0.8380\n",
      "Epoch 129/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3882 - auc: 0.8386\n",
      "Epoch 130/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3862 - auc: 0.8400\n",
      "Epoch 131/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3856 - auc: 0.8385\n",
      "Epoch 132/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3850 - auc: 0.8393\n",
      "Epoch 133/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3866 - auc: 0.8387\n",
      "Epoch 134/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3858 - auc: 0.8398\n",
      "Epoch 135/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3858 - auc: 0.8405\n",
      "Epoch 136/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3822 - auc: 0.8412\n",
      "Epoch 137/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3857 - auc: 0.8392\n",
      "Epoch 138/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3865 - auc: 0.8390\n",
      "Epoch 139/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3853 - auc: 0.8414\n",
      "Epoch 140/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3869 - auc: 0.8396\n",
      "Epoch 141/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3866 - auc: 0.8412\n",
      "Epoch 142/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3824 - auc: 0.8419\n",
      "Epoch 143/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3902 - auc: 0.8366\n",
      "Epoch 144/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3841 - auc: 0.8398\n",
      "Epoch 145/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3874 - auc: 0.8391\n",
      "Epoch 146/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3849 - auc: 0.8399\n",
      "Epoch 147/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3850 - auc: 0.8390\n",
      "Epoch 148/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3844 - auc: 0.8399\n",
      "Epoch 149/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3870 - auc: 0.8392\n",
      "Epoch 150/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3852 - auc: 0.8399\n",
      "Epoch 151/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3827 - auc: 0.8417\n",
      "Epoch 152/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3815 - auc: 0.8422\n",
      "Epoch 153/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3831 - auc: 0.8413\n",
      "Epoch 154/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3826 - auc: 0.8423\n",
      "Epoch 155/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3807 - auc: 0.8428\n",
      "Epoch 156/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3856 - auc: 0.8411\n",
      "Epoch 157/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3821 - auc: 0.8436\n",
      "Epoch 158/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3846 - auc: 0.8396\n",
      "Epoch 159/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3850 - auc: 0.8407\n",
      "Epoch 160/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3830 - auc: 0.8431\n",
      "Epoch 161/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3862 - auc: 0.8403\n",
      "Epoch 162/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3819 - auc: 0.8418\n",
      "Epoch 163/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3846 - auc: 0.8411\n",
      "Epoch 164/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3839 - auc: 0.8432\n",
      "Epoch 165/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3841 - auc: 0.8412\n",
      "Epoch 166/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3829 - auc: 0.8418\n",
      "Epoch 167/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3830 - auc: 0.8415\n",
      "Epoch 168/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3818 - auc: 0.8439\n",
      "Epoch 169/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3845 - auc: 0.8422\n",
      "Epoch 170/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3841 - auc: 0.8416\n",
      "Epoch 171/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3828 - auc: 0.8440\n",
      "Epoch 172/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3842 - auc: 0.8411\n",
      "Epoch 173/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3814 - auc: 0.8404\n",
      "Epoch 174/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3834 - auc: 0.8409\n",
      "Epoch 175/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3821 - auc: 0.8433\n",
      "Epoch 176/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3815 - auc: 0.8451\n",
      "Epoch 177/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3835 - auc: 0.8441\n",
      "Epoch 178/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3795 - auc: 0.8455\n",
      "Epoch 179/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3815 - auc: 0.8436\n",
      "Epoch 180/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3815 - auc: 0.8439\n",
      "Epoch 181/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3836 - auc: 0.8421\n",
      "Epoch 182/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3840 - auc: 0.8412\n",
      "Epoch 183/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3831 - auc: 0.8428\n",
      "Epoch 184/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3814 - auc: 0.8452\n",
      "Epoch 185/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3822 - auc: 0.8448\n",
      "Epoch 186/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3817 - auc: 0.8433\n",
      "Epoch 187/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3826 - auc: 0.8425\n",
      "Epoch 188/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3785 - auc: 0.8448\n",
      "Epoch 189/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3780 - auc: 0.8460\n",
      "Epoch 190/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3812 - auc: 0.8460\n",
      "Epoch 191/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3789 - auc: 0.8458\n",
      "Epoch 192/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3818 - auc: 0.8451\n",
      "Epoch 193/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3830 - auc: 0.8436\n",
      "Epoch 194/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3812 - auc: 0.8453\n",
      "Epoch 195/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3799 - auc: 0.8450\n",
      "Epoch 196/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3805 - auc: 0.8443\n",
      "Epoch 197/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3806 - auc: 0.8434\n",
      "Epoch 198/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3800 - auc: 0.8462\n",
      "Epoch 199/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3803 - auc: 0.8448\n",
      "Epoch 200/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3832 - auc: 0.8439\n",
      "Epoch 201/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3808 - auc: 0.8460\n",
      "Epoch 202/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3790 - auc: 0.8458\n",
      "Epoch 203/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3799 - auc: 0.8461\n",
      "Epoch 204/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3786 - auc: 0.8465\n",
      "Epoch 205/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3795 - auc: 0.8441\n",
      "Epoch 206/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3820 - auc: 0.8444\n",
      "Epoch 207/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3792 - auc: 0.8440\n",
      "Epoch 208/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3794 - auc: 0.8468\n",
      "Epoch 209/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3793 - auc: 0.8455\n",
      "Epoch 210/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3800 - auc: 0.8450\n",
      "Epoch 211/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3814 - auc: 0.8436\n",
      "Epoch 212/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3794 - auc: 0.8464\n",
      "Epoch 213/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3788 - auc: 0.8469\n",
      "Epoch 214/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3775 - auc: 0.8480\n",
      "Epoch 215/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3813 - auc: 0.8446\n",
      "Epoch 216/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3784 - auc: 0.8471\n",
      "Epoch 217/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3773 - auc: 0.8479\n",
      "Epoch 218/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3767 - auc: 0.8485\n",
      "Epoch 219/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3780 - auc: 0.8487\n",
      "Epoch 220/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3797 - auc: 0.8458\n",
      "Epoch 221/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3798 - auc: 0.8448\n",
      "Epoch 222/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3749 - auc: 0.8507\n",
      "Epoch 223/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3787 - auc: 0.8463\n",
      "Epoch 224/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3767 - auc: 0.8485\n",
      "Epoch 225/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3753 - auc: 0.8503\n",
      "Epoch 226/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3756 - auc: 0.8486\n",
      "Epoch 227/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3777 - auc: 0.8461\n",
      "Epoch 228/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3773 - auc: 0.8477\n",
      "Epoch 229/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3777 - auc: 0.8474\n",
      "Epoch 230/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3782 - auc: 0.8464\n",
      "Epoch 231/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3783 - auc: 0.8471\n",
      "Epoch 232/300\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.3770 - auc: 0.8480\n",
      "Epoch 233/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3760 - auc: 0.8485\n",
      "Epoch 234/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3794 - auc: 0.8452\n",
      "Epoch 235/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3760 - auc: 0.8496\n",
      "Epoch 236/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3794 - auc: 0.8480\n",
      "Epoch 237/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3762 - auc: 0.8480\n",
      "Epoch 238/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3796 - auc: 0.8468\n",
      "Epoch 239/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3806 - auc: 0.8461\n",
      "Epoch 240/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3760 - auc: 0.8486\n",
      "Epoch 241/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3795 - auc: 0.8465\n",
      "Epoch 242/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3761 - auc: 0.8474\n",
      "Epoch 243/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3793 - auc: 0.8466\n",
      "Epoch 244/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3792 - auc: 0.8471\n",
      "Epoch 245/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3762 - auc: 0.8497\n",
      "Epoch 246/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3761 - auc: 0.8488\n",
      "Epoch 247/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3800 - auc: 0.8476\n",
      "Epoch 248/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3761 - auc: 0.8502\n",
      "Epoch 249/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3750 - auc: 0.8491\n",
      "Epoch 250/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3771 - auc: 0.8488\n",
      "Epoch 251/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3755 - auc: 0.8505\n",
      "Epoch 252/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3748 - auc: 0.8506\n",
      "Epoch 253/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3743 - auc: 0.8485\n",
      "Epoch 254/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3782 - auc: 0.8487\n",
      "Epoch 255/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3773 - auc: 0.8477\n",
      "Epoch 256/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3739 - auc: 0.8500\n",
      "Epoch 257/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3762 - auc: 0.8507\n",
      "Epoch 258/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3773 - auc: 0.8490\n",
      "Epoch 259/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3794 - auc: 0.8462\n",
      "Epoch 260/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3764 - auc: 0.8496\n",
      "Epoch 261/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3757 - auc: 0.8494\n",
      "Epoch 262/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3774 - auc: 0.8493\n",
      "Epoch 263/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3748 - auc: 0.8511\n",
      "Epoch 264/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3770 - auc: 0.8478\n",
      "Epoch 265/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3749 - auc: 0.8487\n",
      "Epoch 266/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3754 - auc: 0.8491\n",
      "Epoch 267/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3730 - auc: 0.8512\n",
      "Epoch 268/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3774 - auc: 0.8480\n",
      "Epoch 269/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3760 - auc: 0.8482\n",
      "Epoch 270/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3779 - auc: 0.8493\n",
      "Epoch 271/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3747 - auc: 0.8503\n",
      "Epoch 272/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3766 - auc: 0.8492\n",
      "Epoch 273/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3764 - auc: 0.8496\n",
      "Epoch 274/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3739 - auc: 0.8514\n",
      "Epoch 275/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3784 - auc: 0.8470\n",
      "Epoch 276/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3760 - auc: 0.8506\n",
      "Epoch 277/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3759 - auc: 0.8494\n",
      "Epoch 278/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3740 - auc: 0.8511\n",
      "Epoch 279/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3756 - auc: 0.8502\n",
      "Epoch 280/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3719 - auc: 0.8534\n",
      "Epoch 281/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3761 - auc: 0.8496\n",
      "Epoch 282/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3738 - auc: 0.8511\n",
      "Epoch 283/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3758 - auc: 0.8499\n",
      "Epoch 284/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3721 - auc: 0.8521\n",
      "Epoch 285/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3741 - auc: 0.8523\n",
      "Epoch 286/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3709 - auc: 0.8533\n",
      "Epoch 287/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3733 - auc: 0.8520\n",
      "Epoch 288/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3755 - auc: 0.8513\n",
      "Epoch 289/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3747 - auc: 0.8513\n",
      "Epoch 290/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3722 - auc: 0.8517\n",
      "Epoch 291/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3704 - auc: 0.8524\n",
      "Epoch 292/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3729 - auc: 0.8521\n",
      "Epoch 293/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3757 - auc: 0.8484\n",
      "Epoch 294/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3734 - auc: 0.8518\n",
      "Epoch 295/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3747 - auc: 0.8512\n",
      "Epoch 296/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3719 - auc: 0.8533\n",
      "Epoch 297/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3724 - auc: 0.8509\n",
      "Epoch 298/300\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3728 - auc: 0.8536\n",
      "Epoch 299/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3732 - auc: 0.8526\n",
      "Epoch 300/300\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.3746 - auc: 0.8517\n"
     ]
    }
   ],
   "source": [
    "keras_grid_search = grid(estimator, scoring, 3, X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8403553637407537"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 5000,\n",
       " 'dropout_rate': 0.1,\n",
       " 'epochs': 300,\n",
       " 'init_mode': 'glorot_normal',\n",
       " 'learn_rate': 0.1,\n",
       " 'neurons': 100,\n",
       " 'optimizer': 'SGD'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7359420279684008"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(keras_grid_search.best_estimator_.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJPLOFKeB50Q"
   },
   "outputs": [],
   "source": [
    "# Preprocess on test-set -> Evaluate\n",
    "# scaler = scaler()\n",
    "# prep_train = scaler.fit_transform(train)\n",
    "\n",
    "# prep_test = scaler.transform(test)\n",
    "# prep_test = scaler.fit_transform(test) # X -> Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBffQvGxDWgq"
   },
   "outputs": [],
   "source": [
    "# Clustering\n",
    "# WSS, BSS, Entropy, Purity\n",
    "# Kmeans -> 3~5\n",
    "# df.desrcibe() for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Preprocessing Test dataset\n",
    "\n",
    "# test_df1 = test_df.iloc[:, :45]\n",
    "# prep_tf1,tff = preProcessing1(test_df1, y)\n",
    "# prep_tf1.index = test_df.index\n",
    "\n",
    "# test_df2 = test_df.iloc[:, 45:90]\n",
    "# prep_tf2,tff = preProcessing2(test_df2, y)\n",
    "# prep_tf2.index = test_df.index\n",
    "\n",
    "# test_df3 = test_df.iloc[:, 90:135]\n",
    "# prep_tf3,tff = preProcessing3(test_df3, y)\n",
    "# prep_tf3.index = test_df.index\n",
    "\n",
    "# test_df4 = test_df.iloc[:,135:]\n",
    "# prep_tf4,tff = preProcessing4(test_df4, y)\n",
    "# prep_tf4.index = test_df.index\n",
    "\n",
    "# test_df1 = test.iloc[:, :45]\n",
    "# def test_prep1(df: pd.DataFrame, tf: list) -> pd.DataFrame:\n",
    "#   for each in tf:\n",
    "#     df = each.transform(df)\n",
    "\n",
    "#   return df\n",
    "\n",
    "# prep_tf = pd.concat([prep_tf1, prep_tf2, prep_tf3, prep_tf4], axis=1)\n",
    "# prep_tf\n",
    "\n",
    "# [Jaewoong]\n",
    "# extract numberical columns\n",
    "# discretize\n",
    "# feature selection\n",
    "# -> optimal subset of features\n",
    "\n",
    "\n",
    "# [Uma]-Done\n",
    "# Oversampling or Undersampling (=Resampling)\n",
    "# negative class = 75%\n",
    "# positive class = 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Preprocessing Test dataset\n",
    "\n",
    "# test_df1 = test_df.iloc[:, :45]\n",
    "# prep_tf1,tff = preProcessing1(test_df1, y)\n",
    "# prep_tf1.index = test_df.index\n",
    "\n",
    "# test_df2 = test_df.iloc[:, 45:90]\n",
    "# prep_tf2,tff = preProcessing2(test_df2, y)\n",
    "# prep_tf2.index = test_df.index\n",
    "\n",
    "# test_df3 = test_df.iloc[:, 90:135]\n",
    "# prep_tf3,tff = preProcessing3(test_df3, y)\n",
    "# prep_tf3.index = test_df.index\n",
    "\n",
    "# test_df4 = test_df.iloc[:,135:]\n",
    "# prep_tf4,tff = preProcessing4(test_df4, y)\n",
    "# prep_tf4.index = test_df.index\n",
    "\n",
    "# prep_tf = pd.concat([prep_tf1, prep_tf2, prep_tf3, prep_tf4], axis=1)\n",
    "# prep_tf\n",
    "\n",
    "# df1 = df.iloc[:, :45]\n",
    "# def train_prep1(df: pd.DataFrame) -> (pd.DataFrame, list):\n",
    "#   # Examples\n",
    "#   transformer1 = SimpleImputer()\n",
    "#   df = transformer1.fit_transform(df)\n",
    "#   transformer2 = StandardScaler()\n",
    "#   df = transformer2.fit_transform(df)\n",
    "#   # MDLP\n",
    "#   # LinearRegression.fit_transform\n",
    "#   # ...\n",
    "\n",
    "#   return df, [transformer1, transformer2]\n",
    "# prep_df1, tf1 = train_prep1(df1)\n",
    "\n",
    "# # Do the same for 2~4...\n",
    "\n",
    "# prep_df = pd.concat([prep_df1, prep_df2, prep_df3, prep_df4], axis=1)\n",
    "\n",
    "\n",
    "# test_df1 = test.iloc[:, :45]\n",
    "# def test_prep1(df: pd.DataFrame, tf: list) -> pd.DataFrame:\n",
    "#   for each in tf:\n",
    "#     df = each.transform(df)\n",
    "\n",
    "#   return df\n",
    "# prep_test_df1 = test_prep1(test_df1, tf1)\n",
    "# # Do the same for 2~4...\n",
    "# prep_test_df = pd.concat([prep_test_df1, prep_test_df2, prep_test_df3, prep_test_df4], axis=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "wids_Datathon_2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cmpe255-project",
   "language": "python",
   "name": "cmpe255-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
